# 结营项目笔记

## 任务内容

完成四个视频的篮球跟随任务，要求如下：

+ 使用yolov11完成篮球的识别并输出篮球的位置，帧率不低于20帧，**必须使用Python版本的torch，C++版本可能无法完成帧率要求**
+ 使用卡尔曼滤波器进行插帧，要求插帧结果不得低于识别帧率的3倍，**滤波器必须使用Eigen完成，否则视为结营项目未完成**
+ 将上述结果进行可视化，方法不限
+ 前四个视频为必做任务，最后一个视频为选做任务
+ rgb视频与depth视频流理论上是对齐的，但不排除个别帧未对齐的情况，请谨慎使用depth视频流

## 目前实现的功能

+ 通过yolov11模型进行了视频中的球的检测，能够输出球在像素坐标系下的中心点坐标，显示识别的球的id,显示框和轨迹（py）
+ 通过calibration里的视频得到了相机的内参和外参，并用json存储，用solvePnP将像素坐标系下的球的中心点坐标转换到相机坐标系下。(cpp)
+ 通过卡尔曼滤波对球的三维坐标进行了滤波，滤波后的结果再次转回到像素坐标系下，通过ros2的topic发布出来。(cpp)
+ 通过python的ros2节点订阅了卡尔曼滤波后的结果，并且在视频上显示了滤波后的轨迹。(py)

## 目前存在的问题

+ 识别帧率有待提高
+ 多球分离效果不佳，一个球出边框丢失后在进来就是一个新id,影响visualizer.py点迹颜色
+ 卡尔曼滤波器的点迹有点滞后（改一下起始时间）
+ test2那个篮球上下飞的太快了识别效果不好

## 尝试的改进：

+ 调整参数，测量噪声和过程噪声
+ 优化id分配策略，不然轨迹会断
